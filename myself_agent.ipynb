{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKdfQYPRO2XuFpgrG5HgRv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tothegump/Dash-User-Contributions/blob/master/myself_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1JF-4RuxeDAR"
      },
      "outputs": [],
      "source": [
        "import openai, os\n",
        "\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# learn Agents"
      ],
      "metadata": {
        "id": "sB-k5MU5i4-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 输入源文章，判断语言\n",
        "2. 划分段落，总结核心观点\n",
        "3. 写新的 outline\n",
        "4. 重要内容\n",
        "5. 重新写文章"
      ],
      "metadata": {
        "id": "EhZJBUUejCEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define your desired data structure.\n",
        "class Blogger(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")"
      ],
      "metadata": {
        "id": "OGZUfaKTVIlW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Define a custom prompt to provide instructions and any additional context.\n",
        "# 1) You can add examples into the prompt template to improve extraction quality\n",
        "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
        "#    about the document from which the text was extracted.)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm. \"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"If you do not know the value of an attribute asked \"\n",
        "            \"to extract, return null for the attribute's value.\",\n",
        "        ),\n",
        "        # ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
        "        MessagesPlaceholder(\"examples\"),  # <-- EXAMPLES!\n",
        "        # ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "4DEPNt21i7LQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# my agents\n"
      ],
      "metadata": {
        "id": "1SvHOA0Kf_6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(api_key=ok)\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n"
      ],
      "metadata": {
        "id": "RqmGlN6_1lt1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IdeaGen(BaseModel):\n",
        "    point: str = Field(description=\"the point around this topic\")\n",
        "    outline: str = Field(description=\"the outline about the point\")\n",
        "\n",
        "\n",
        "class IdeaList(BaseModel):\n",
        "    idea_list: list[IdeaGen] = Field(description=\"the points and outline around this topic\")"
      ],
      "metadata": {
        "id": "Hpy2JFNXV3wm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"a blog writer\"\n",
        "prompt_generator = PromptTemplate.from_template(\"\"\"\n",
        "As a prompt expert, you pay close attention to several characteristics of a prompt:\n",
        "Clarity and Definiteness\n",
        "Clear Background Context\n",
        "Clear Steps or Instructions\n",
        "Presence of Limiting Conditions\n",
        "Use of Separators to Distinguish Independent Sections\n",
        "Encouraging the Model to Check if Conditions are Met\n",
        "===\n",
        "now make a prompt about `{target}`, if you have something not clear, do not answer, just ask for making the target clear\n",
        "\"\"\")\n",
        "res = prompt_generator | llm"
      ],
      "metadata": {
        "id": "xzJI66vj-N_p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = res.invoke({\"target\": target})"
      ],
      "metadata": {
        "id": "7hbw63t__U8k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ol2-gBE_uu0",
        "outputId": "714455b9-eee9-44ee-ec68-cf2d88feceea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"1. Share your top tips for balancing work and blogging.\\n2. Discuss the importance of consistency in blog content.\\n3. Write a review of your favorite blogging tools and resources.\\n4. Share your experience with building a successful blog from scratch.\\n5. Discuss the benefits of collaborating with other bloggers or brands.\\n6. Write about the impact of social media on your blog's growth.\\n7. Share your favorite blogging mistakes and what you learned from them.\\n8. Discuss the importance of SEO and how it can help drive traffic to your blog.\\n9. Write about the challenges of staying motivated and inspired as a blogger.\\n10. Share your process for brainstorming and creating blog post ideas.\", response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 16, 'total_tokens': 154}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-37b883f5-038c-463f-bc3f-0d6898c61faa-0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzzxcx6x_pwm",
        "outputId": "b4bdd618-1f5e-4720-c7da-17f2a5a35aa9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please write a blog post about the impact of social media on mental health. Make sure to include statistics and case studies to support your argument. Additionally, discuss potential solutions to mitigate the negative effects of social media on mental well-being. Be sure to cite your sources and use proper formatting for your post.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "target = ('a ai anime filter website. You can upload a photo, '\n",
        "'and then get a anime image with styles like Clay, 3D, video game, Emoji, pixels, toy, and so on.'\n",
        ")\n",
        "\n",
        "idea_sys = (\n",
        "        \"As a creative ideas expert, \"\n",
        "        \"your task is to generate several innovative approaches related to the topic.\"\n",
        "        \" Each approach should be explored from a unique angle to \"\n",
        "        \"provide a multi-faceted perspective on the theme.\"\n",
        "        \"\\n===\\n{format_instructions}\\n===\\n topic: `{topic}`\"\n",
        "        )\n",
        "# parser = JsonOutputParser(pydantic_object=IdeaGen)\n",
        "parser = JsonOutputParser(pydantic_object=IdeaList)\n",
        "idea_prompt = PromptTemplate(\n",
        "    template=idea_sys, input_variables=[\"topic\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "uvZ3RTv4XTlN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{target=}')\n",
        "chain = idea_prompt | llm | parser\n",
        "chain.invoke({\"topic\": target})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3pHYz0YfW7",
        "outputId": "47a1cdbd-7e50-457f-a589-c608071ca2ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target='a blog writer'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idea_list': [{'point': 'Utilize storytelling techniques to engage readers',\n",
              "   'outline': 'Craft narratives that captivate the audience and evoke emotions to keep them coming back for more'},\n",
              "  {'point': 'Experiment with different writing styles and tones',\n",
              "   'outline': 'Explore a variety of tones from formal to conversational, and styles such as listicles, how-tos, and personal essays to cater to diverse reader preferences'},\n",
              "  {'point': 'Collaborate with guest bloggers and experts',\n",
              "   'outline': 'Bring fresh perspectives and expertise to the blog by inviting guest contributors to share their insights and knowledge with the audience'},\n",
              "  {'point': 'Optimize SEO for increased visibility',\n",
              "   'outline': 'Implement keyword research, meta tags, and backlinking strategies to improve search engine rankings and attract more organic traffic to the blog'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blog_prompt = \"\"\"\n",
        "You are a blog writer, are good at write articles according given {point} and {outline}.\n",
        "\n",
        "\"\"\"\n",
        "cn = \"\"\"\n",
        "Prompt:\n",
        "\n",
        "角色： 博客作家 (Bó kè jiā zuò zhě)\n",
        "\n",
        "任务： 撰写一篇博客文章 (Zhuān xiě yī piān bó kè wén zhāng)\n",
        "\n",
        "目标： 清晰地解释一件事情 (Qīng xī de jiě shì yī jiàn shì qíng)\n",
        "\n",
        "给定信息：\n",
        "\n",
        "观点 (Guǎn diǎn)\n",
        "大纲 (Dà gāng)\n",
        "要求：\n",
        "\n",
        "遵循博客文章写作的最佳实践 (Zūncún bó kè wén zhāng xiě zuò de zuì jiā shí xiàn)\n",
        "使用清晰简洁的语言 (Shǐ yòng qīng xī jiǎn jié de yǔ yán)\n",
        "举例说明 (Jǔ lì shuo míng)\n",
        "使文章引人入胜 (Shǐ wén zhāng yǐn rén rù shèng)\n",
        "示例：\n",
        "\n",
        "您可以选择一个您熟悉的话题，并就该话题表达您的观点。\n",
        "您可以使用大纲来组织您的想法，并确保您的文章内容连贯。\n",
        "您可以使用示例来说明您的观点，并使您的文章更具吸引力。\n",
        "提示：\n",
        "\n",
        "在开始写作之前，请务必仔细阅读给定信息。\n",
        "考虑您的目标受众，并确保您的文章适合他们。\n",
        "使用各种写作技巧来使您的文章引人入胜。\n",
        "校对您的文章以确保没有错误。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Dsk2pACtjh-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idea_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", idea_sys),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "idea_chain = idea_prompt | llm"
      ],
      "metadata": {
        "id": "pA2QdejIMunK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_writer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"\"\"\n",
        "Please write a blog post about the impact of social media on mental health.\n",
        "Make sure to include statistics and case studies to support your argument.\n",
        "Additionally, discuss potential solutions to mitigate the negative effects of social media on mental well-being.\n",
        "Be sure to cite your sources and use proper formatting for your post.\n",
        "\"\"\"),\n",
        "(\"user\", \"{input}\")\n",
        "     ])"
      ],
      "metadata": {
        "id": "4ZiCv2yDI4bP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = blog_writer_prompt | llm\n",
        "chain.invoke({\"input\": \"write a blog\"})"
      ],
      "metadata": {
        "id": "FFhPYxewNack"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn2en_prompt = \"\"\"\n",
        "请将以下中文段落翻译成英文。在翻译过程中，请遵循以下步骤以确保翻译的准确性和流畅性：\n",
        "理解原文：阅读中文段落，确保完全理解其含义。\n",
        "词汇对应：识别并确定每个中文单词或短语的准确英文对应词汇。{term_option}\n",
        "语法结构：保持英文语法的正确性，注意时态、语态和主谓一致。\n",
        "流畅性检查：确保翻译后的英文读起来自然流畅，符合英语表达习惯。\n",
        "文化适应性：适当调整翻译，以传达原文的文化内涵和语境。\n",
        "校对：完成翻译后，仔细校对以避免拼写和语法错误。\n",
        "中文文章如下：```\n",
        "{article}\n",
        "```\n",
        "\"\"\"\n",
        "pt = ChatPromptTemplate.from_messages([\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
        "])\n",
        "pt = PromptTemplate.from_template()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "N_LuZhEA8oh8",
        "outputId": "d204efbd-2212-4c77-e4e3-46a284923882"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ChatPromptTemplate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-609365295eff>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m pt = ChatPromptTemplate.from_messages([\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mMessagesPlaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"chat_history\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ChatPromptTemplate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "9Y1Ms0Dn8dMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"how can langsmith help with testing?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXvyEGZh6Ku2",
        "outputId": "8b0b1263-bfc5-4110-f183-be55ec1d0039"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Langsmith can help with testing in the following ways:\\n\\n1. Automated testing: Langsmith can be used to write automated test scripts for software applications, enabling developers to quickly and efficiently test their code.\\n\\n2. Test data generation: Langsmith can generate test data for a wide range of scenarios, helping developers to ensure that their software is robust and can handle various inputs.\\n\\n3. Performance testing: Langsmith can be used to simulate high loads on a system, allowing developers to test the performance of their applications under stress.\\n\\n4. Integration testing: Langsmith can be used to test the integration of different components of a software application, ensuring that they work together seamlessly.\\n\\n5. Regression testing: Langsmith can help automate regression testing, allowing developers to quickly identify and fix any issues that arise when changes are made to the codebase.\\n\\nOverall, Langsmith can help streamline the testing process, improve the quality of software applications, and ultimately save time and resources for development teams.', response_metadata={'token_usage': {'completion_tokens': 194, 'prompt_tokens': 15, 'total_tokens': 209}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_a450710239', 'finish_reason': 'stop', 'logprobs': None}, id='run-160a03e2-be72-41c8-92a8-bba36f12885c-0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en2cn_prompt = \"\"\"\n",
        "\n",
        "请将以下英文段落翻译成中文。在翻译过程中，请遵循以下步骤以确保翻译的准确性和自然性：\n",
        "\n",
        "理解原文：仔细阅读英文段落，确保完全理解其含义和上下文。\n",
        "词汇翻译：将英文单词或短语逐一翻译成中文，注意选择最合适的中文词汇。\n",
        "语法调整：根据中文的语法习惯调整句子结构，确保翻译后的中文句子语法正确。\n",
        "保持原意：在翻译过程中，确保保留原文的意思和语气。\n",
        "文化适应：适当调整翻译，使其更符合中文读者的文化背景和阅读习惯。\n",
        "流畅性优化：确保翻译后的中文读起来流畅自然，无生硬的直译表达。\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cn2en_prompt = \"\"\"\n",
        "请将以下中文段落翻译成英文。在翻译过程中，请遵循以下步骤以确保翻译的准确性和流畅性：\n",
        "理解原文：阅读中文段落，确保完全理解其含义。\n",
        "词汇对应：识别并确定每个中文单词或短语的准确英文对应词汇。{term_option}\n",
        "语法结构：保持英文语法的正确性，注意时态、语态和主谓一致。\n",
        "流畅性检查：确保翻译后的英文读起来自然流畅，符合英语表达习惯。\n",
        "文化适应性：适当调整翻译，以传达原文的文化内涵和语境。\n",
        "校对：完成翻译后，仔细校对以避免拼写和语法错误。\n",
        "中文文章如下：```\n",
        "{article}\n",
        "```\n",
        "\"\"\"\n",
        "term_option_find = \"对专业词汇需要找到对应的中文词，如果没有则保留原词\"\n",
        "term_option_keep = \"对专业词汇需要要保留原词\"\n",
        "cn2en_prompt_en = \"\"\"\n",
        "Please translate the following Chinese paragraph into English. During the translation process, please follow the steps below to ensure the accuracy and fluency of the translation:\n",
        "\n",
        "Understand the Original Text: Read the Chinese paragraph and make sure you fully understand its meaning.\n",
        "Lexical Correspondence: Identify and determine the accurate English corresponding words or phrases for each Chinese word or phrase. {term_option}\n",
        "Grammar Structure: Maintain the correctness of English grammar, paying attention to tense, voice, and subject-verb agreement.\n",
        "Fluency Check: Ensure that the translated English reads naturally and fluently, conforming to English expression habits.\n",
        "Cultural Adaptability: Appropriately adjust the translation to convey the original text's cultural content and context.\n",
        "Proofreading: After completing the translation, carefully proofread to avoid any spelling or grammatical errors.\n",
        "There is the paragraph:\n",
        "```{article}```\n",
        "\"\"\"\n",
        "term = \"\"\"When encountering professional terminology, one should attempt to find the corresponding Chinese term. If no equivalent is available, the original term should be retained.\"\"\"\n",
        "term_option_keep = \"When encountering professional terminology, the original term should be retained\"\n",
        "\n",
        "\n",
        "cn_article = \"\"\" \"\"\"\n",
        "\n",
        "en_article = \"\"\" \"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "m9HmuJi4gCku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip install\n"
      ],
      "metadata": {
        "id": "xvuPou02fabk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ok = userdata.get('openai_first')"
      ],
      "metadata": {
        "id": "ftkd65_IffZA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n",
        "!pip install openai tiktoken backoff\n",
        "!pip install llama-index langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eW99TS1fdCN",
        "outputId": "af2edf7c-62a6-4e99-bd6c-0e3842ed117e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.46 (from langchain-openai)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.24.0 (from langchain-openai)\n",
            "  Downloading openai-1.25.2-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.46->langchain-openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain-openai)\n",
            "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.46->langchain-openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.50 langchain-openai-0.1.6 langsmith-0.1.54 openai-1.25.2 orjson-3.10.3 packaging-23.2 tiktoken-0.6.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.34-py3-none-any.whl (6.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.34 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.34-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.16-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.20-py3-none-any.whl (37 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.50)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.25.2)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.34->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.34->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (0.27.0)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.34->llama-index)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (9.4.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (4.11.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.34->llama-index) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.2-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.34->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.34->llama-index) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.34->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.34->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.34->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.34->llama-index) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.34->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.7.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.34->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.34->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.34->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.34->llama-index) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.34->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, dirtyjson, pypdf, mypy-extensions, marshmallow, deprecated, typing-inspect, llamaindex-py-client, dataclasses-json, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, langchain-community, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed dataclasses-json-0.6.5 deprecated-1.2.14 dirtyjson-1.0.8 langchain-0.1.17 langchain-community-0.0.36 langchain-text-splitters-0.0.1 llama-index-0.10.34 llama-index-agent-openai-0.2.3 llama-index-cli-0.1.12 llama-index-core-0.10.34 llama-index-embeddings-openai-0.1.9 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.16 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.20 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.2 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 pypdf-4.2.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        }
      ]
    }
  ]
}